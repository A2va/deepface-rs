#!/usr/bin/env -S uv run --script

# /// script
# dependencies = [
#   "pandas>=2.3",
#   "matplotlib>=3.10",
#   "scipy>=1.16",
#   "scikit-learn>=1.7",
#   "tabulate>=0.9",
#   "chefboost==0.0.19"
# ]
# ///
#
# Learn more about Astral's UV tool at
# https://docs.astral.sh/uv/guides/scripts/#declaring-script-dependencies
#
# Documentation:
#   Compute optimal distance thresholds and confidence values
#   for a face recognition model based on its distance CSV file.
#
#   Input:
#       <model>.csv generated by the Rust distance tool.
#       The CSV contains:
#         - file_x, file_y
#         - decision (1 / 0)
#         - cosine distance
#         - euclidean distance
#         - euclidean_l2 distance
#
#   Output:
#       - Console summary of thresholds & accuracy
#       - Optionally plots or tables (if enabled)
#       - Can be copied directly into the Rust codebase
#
#   Usage:
#       uv run compute-thresholds --plot --info facenet512.csv
#
#   This produces model-specific thresholds for use directly
#   inside deepface-rs' RecognitionModel configuration.

import argparse
import math
import os
import re
import sys
import tempfile
from pathlib import Path
from textwrap import dedent
from typing import Any, Dict

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from chefboost import Chefboost as chef
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix


def find_threshold(df: pd.DataFrame):
    old_cwd = os.getcwd()
    with tempfile.TemporaryDirectory() as dir:
        # Tricks to make chefboost generates the rule in temporary directory
        os.chdir(dir)
        sys.path.insert(0, dir)

        config = {"algorithm": "C4.5"}
        tmp_df = (
            df[["distance", "decision"]].rename(columns={"decision": "Decision"}).copy()
        )
        tmp_df["Decision"] = tmp_df["Decision"].replace({1: "Yes", 0: "No"})
        model = chef.fit(tmp_df, config, silent=True)

        # Extract the threshold from the file that chefboost generates in output/rules/rules.py
        with open("outputs/rules/rules.py", "r") as f:
            content = f.read()

        # Look specifically for obj[0] > number OR obj[0] <= number
        pattern = r"obj\[0\]\s*(?:>|<=)\s*([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)"
        match = re.search(pattern, content)
        threshold = float(match.group(1)) if match else None
        assert threshold is not None

        os.chdir(old_cwd)
        return threshold


def compute_stats(
    df: pd.DataFrame, metric_name: str, threshold: float
) -> Dict[str, float]:
    """Compute precision, recall, f1 and accuracy for a dataset using a threshold."""
    df = df.copy()
    df["prediction"] = 0
    df.loc[df["distance"] <= threshold, "prediction"] = 1

    cm = confusion_matrix(df["decision"].values, df["prediction"].values)
    if cm.size != 4:
        # Not enough classes; return zeroed stats
        return {"precision": 0.0, "recall": 0.0, "f1": 0.0, "accuracy": 0.0}

    tn, fp, fn, tp = cm.ravel()
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    accuracy = (tp + tn) / (tn + fp + fn + tp) if (tn + fp + fn + tp) > 0 else 0.0
    f1 = (
        2 * (precision * recall) / (precision + recall)
        if (precision + recall) > 0
        else 0.0
    )

    return {"precision": precision, "recall": recall, "f1": f1, "accuracy": accuracy}


def fit_confidence_model(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Fit a logistic model to predict the binary label from distance, then
    compute confidence scores (0..100) and return parameters + mins/maxes.
    """
    df = df.copy()
    max_value = df["distance"].max()
    X = df["distance"].values.reshape(-1, 1).astype(float)
    y = df["prediction"].values.astype(int)

    # normalize the distance values before feeding them to the model
    if max_value > 1:
        X = X / max_value

    model = LogisticRegression().fit(X, y)
    w = float(model.coef_[0][0])
    b = float(model.intercept_[0])

    # Compute confidences
    distances = df["distance"]
    if max_value > 1:
        distances = distances / max_value

    z = w * distances + b
    df["confidence"] = 100 / (1 + np.exp(-z))

    return {
        "w": w,
        "b": b,
        "normalizer": float(max_value) if max_value > 0 else 1.0,
        "denorm_max_true": float(
            df.loc[df["prediction"] == 1, "confidence"].max() or 0.0
        ),
        "denorm_min_true": float(
            df.loc[df["prediction"] == 1, "confidence"].min() or 0.0
        ),
        "denorm_max_false": float(
            df.loc[df["prediction"] == 0, "confidence"].max() or 0.0
        ),
        "denorm_min_false": float(
            df.loc[df["prediction"] == 0, "confidence"].min() or 0.0
        ),
    }


def print_rust_thresholds(thresholds: Dict[str, float]):
    print("\n==== Thresholds (copy into deepface-rs) ====\n")
    print(
        dedent(f"""
        ModelThreshold {{
            cosine: {thresholds["cosine"]:.6f},
            euclidean: {thresholds["euclidean"]:.6f},
            euclidean_l2: {thresholds["euclidean_l2"]:.6f},
            angular: 0.0,
        }},
    """).strip()
    )


def print_rust_confidence_table(conf: Dict[str, Any]):
    print("\n==== Confidence Models (copy into deepface-rs) ====\n")

    mapping = {
        "cosine": "DistanceMethod::Cosine",
        "euclidean": "DistanceMethod::Euclidean",
        "euclidean_l2": "DistanceMethod::EuclideanL2",
    }

    for key, variant in mapping.items():
        c = conf[key]
        print(
            dedent(f"""
            {variant} => ModelConfidence {{
                w: {c["w"]:.6f},
                b: {c["b"]:.6f},
                normalizer: {c["normalizer"]:.6f},
                denorm_max_true: {c["denorm_max_true"]:.6f},
                denorm_min_true: {c["denorm_min_true"]:.6f},
                denorm_max_false: {c["denorm_max_false"]:.6f},
                denorm_min_false: {c["denorm_min_false"]:.6f},
            }},
        """).strip()
        )


def main(args):
    df = pd.read_csv(args.csv)
    recognition_model = Path(args.csv).stem

    metrics = ["cosine", "euclidean", "euclidean_l2"]
    threshold_metric = {}
    confidence_metrics = {}

    stats_data = []

    for metric in metrics:
        df_metric = df[[metric, "decision"]].rename(columns={metric: "distance"})

        if args.plot:
            ax = df_metric[df_metric.decision == 1].distance.plot.kde(label="Yes")
            df_metric[df_metric.decision == 0].distance.plot.kde(ax=ax, label="No")

            # Add a legend and title for clarity (optional but recommended)
            plt.title("Kernel Density Estimate of Distance by Decision")
            plt.xlabel("Distance")
            plt.legend()

            plt.savefig(
                f"{recognition_model}_{metric}_plot.png", bbox_inches="tight", dpi=100
            )
            plt.close()

        threshold = find_threshold(df_metric.copy(deep=True))
        threshold_metric[metric] = threshold

        # Now that the optimal threshold has been found, add a prediction column based on it
        df_metric["prediction"] = 0
        idx = df_metric[df_metric.distance <= threshold].index
        df_metric.loc[idx, "prediction"] = 1

        # stats
        s = compute_stats(df_metric, metric, threshold)
        stats_data.append({"Metric": metric, **s})

        # fit confidence model
        conf = fit_confidence_model(df_metric)
        confidence_metrics[metric] = conf

    # Display the stats table is provided
    if args.info:
        print("\n==== Metric Statistics Summary ====")
        stats_df = pd.DataFrame(stats_data)
        print(stats_df.to_markdown(index=False))

    print()

    print_rust_thresholds(threshold_metric)
    print_rust_confidence_table(confidence_metrics)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Finds the tipping point for a recognition model, by taking a csv as input",
    )

    parser.add_argument("csv")
    parser.add_argument(
        "-p",
        "--plot",
        action="store_true",
        help="Export a density graphic image per distance metric",
    )
    parser.add_argument(
        "-i",
        "--info",
        action="store_true",
        help="Dislay some information for each metric",
    )

    args = parser.parse_args()

    main(args)
