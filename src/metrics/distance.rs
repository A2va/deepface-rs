use burn::prelude::{Backend, ElementConversion, Tensor, ToElement};
use burn::tensor::linalg::{cosine_similarity, l2_norm, DEFAULT_EPSILON};

/// All distance methods supported in [`distance`].
#[derive(Clone, Copy)]
pub enum DistanceMethod {
    Cosine,
    Euclidean,
    EuclideanL2,
    Angular,
}

// TODO Implement batching
fn angular_distance<B: Backend, const D: usize>(
    x1: Tensor<B, D>,
    x2: Tensor<B, D>,
    dim: i32,
    eps: Option<B::FloatElem>,
) -> Tensor<B, D> {
    let eps = eps.unwrap_or_else(|| B::FloatElem::from_elem(DEFAULT_EPSILON));

    // Convert negative dimension to positive
    let dim_idx = if dim < 0 { D as i32 + dim } else { dim } as usize;

    // Compute dot product: sum(x1 * x2) along the specified dimension
    let dot_product = (x1.clone() * x2.clone()).sum_dim(dim_idx);

    // Compute L2 norms: ||x1|| and ||x2||
    let norm_x1 = l2_norm(x1, dim_idx);
    let norm_x2 = l2_norm(x2, dim_idx);

    // Calculate the denominator (product of the norms) with epsilon to avoid division by zero
    let denominator = norm_x1.clamp_min(eps) * norm_x2.clamp_min(eps);

    let similarity = dot_product / denominator;
    // np.arccos(similarity) / np.pi
    todo!("TODO Wait for burn to have arccos")
}

fn euclidean_similarity<B: Backend, const D: usize>(
    emb1: Tensor<B, D>,
    emb2: Tensor<B, D>,
    dim: i32,
) -> Tensor<B, D> {
    // Convert negative dimension to positive
    let dim_idx = if dim < 0 { D as i32 + dim } else { dim } as usize;

    let t = emb1 - emb2;
    l2_norm(t, dim_idx)
}

fn l2_normalize<B: Backend, const D: usize>(
    x: Tensor<B, D>,
    dim: i32,
    eps: Option<B::FloatElem>,
) -> Tensor<B, D> {
    let eps = eps.unwrap_or_else(|| B::FloatElem::from_elem(DEFAULT_EPSILON));
    // Convert negative dimension to positive
    let dim_idx = if dim < 0 { D as i32 + dim } else { dim } as usize;

    let norm = l2_norm(x.clone(), dim_idx);
    x / (norm + eps)
}

/// Compare two emdeddings tensor with the specified method and return the distance between them.
/// Make sure that the two embeddings have been generated by the same model.
pub fn distance<B: Backend, const D: usize>(
    x1: Tensor<B, D>,
    x2: Tensor<B, D>,
    method: DistanceMethod,
) -> f32 {
    match method {
        DistanceMethod::Cosine => 1 - cosine_similarity(x1, x2, -1, None),
        DistanceMethod::Euclidean => euclidean_similarity(x1, x2, -1),
        DistanceMethod::EuclideanL2 => {
            let x1_norm = l2_normalize(x1, -1, None);
            let x2_norm = l2_normalize(x2, -1, None);
            euclidean_similarity(x1_norm, x2_norm, -1)
        }
        DistanceMethod::Angular => angular_distance(x1, x2, -1, None),
    }
    .into_scalar()
    .to_f32()
}
